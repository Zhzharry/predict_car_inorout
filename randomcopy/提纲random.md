
## 方案二：随机森林分类方案
### 一、方案核心思路
随机森林是基于集成学习思想的非线性分类模型，通过构建多棵决策树并融合预测结果，提升模型的泛化能力和抗过拟合能力。本方案利用随机森林的特征重要性评估功能自动筛选关键特征，无需依赖数值分解技术；通过bootstrap抽样和特征随机选择机制，降低单棵决策树的方差，增强模型对传感器数据噪声和非线性关联的适应性；最终通过多棵决策树的投票机制输出分类结果，实现三类场景的精准识别。

### 二、分步实施流程
#### （一）数据准备与预处理
1. **数据加载与拆分**：同方案一的“数据加载”和“数据拆分”步骤，确保训练子集、本地测试子集的类别分布均衡。
2. **数据清洗**：处理特征矩阵中的异常值（如超出3倍标准差的极端值）和缺失值（采用均值填充或中位数填充），避免异常数据对决策树分裂的干扰。
3. **特征预处理**：无需额外降维，直接保留原始特征矩阵（或仅进行标准化处理），利用随机森林的内置机制自动处理特征冗余和非线性关联。

#### （二）特征重要性评估与筛选
1. **初始模型训练**：构建初始随机森林模型（设置合理的决策树数量、树深度等超参数），使用训练子集进行训练。
2. **特征重要性计算**：通过随机森林的特征重要性评估指标（如Gini系数减少量、信息增益），计算每个特征对分类任务的贡献度。
3. **关键特征筛选**：按特征重要性降序排序，保留前60%-80%的特征（或设置重要性阈值），剔除贡献度极低的冗余特征，简化模型结构，提升计算效率。

#### （三）随机森林模型训练与超参数优化
1. **超参数设置**：明确核心超参数包括决策树数量（n_estimators）、决策树最大深度（max_depth）、每棵树的最大特征数（max_features）、叶节点最小样本数（min_samples_leaf）等。
2. **超参数优化**：采用网格搜索或随机搜索方法，在训练子集上进行交叉验证（如5折交叉验证），寻找最优超参数组合，平衡模型的拟合能力与泛化能力。
3. **最终模型训练**：使用最优超参数组合构建最终随机森林模型，基于筛选后的关键特征和训练子集进行充分训练，输出训练完成的模型。

#### （四）模型预测与结果生成
1. **本地测试预测**：将筛选后的本地测试子集特征矩阵输入训练好的随机森林模型，通过多棵决策树的投票机制得到预测标签（得票最多的类别为最终预测结果）。
2. **验证集预测**：对验证集的每个文件执行“数据清洗→特征筛选→模型预测”流程，为每个样本追加labelArea列，生成符合格式要求的预测结果文件，确保与训练集标签格式一致。

#### （五）模型评估（适配作业4项评价指标）
1. **预测准确率**：计算本地测试子集的预测准确率，结合实时检测约束统计有效检测率（排除未在规定时间窗口内检测到的样本）。
2. **检测时延**：模拟实时场景，统计单样本预测的平均耗时，重复1000次取均值，确保不依赖未来数据。
3. **计算效率**：统计本地测试子集的整体预测耗时，计算单位时间内的样本处理量，评估模型的计算速度。
4. **模型大小**：统计随机森林的参数量（每棵决策树的节点数、分裂阈值等），估算模型文件存储大小，评估轻量化程度。
