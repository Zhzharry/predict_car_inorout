"""
GNNæ¨¡å‹è°ƒç”¨ä¸ç»“æœåˆ†ææ¨¡å—
åŠŸèƒ½ï¼šæ¨¡å‹é¢„æµ‹ã€ç»“æœç”Ÿæˆã€è¯„ä¼°æŒ‡æ ‡è®¡ç®—ï¼ˆå‡†ç¡®ç‡ã€æ—¶å»¶ã€è®¡ç®—æ•ˆç‡ã€æ¨¡å‹å¤§å°ï¼‰
"""

import pandas as pd
import numpy as np
import os
import time
import json
import torch
from torch_geometric.data import Batch
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from a_æ•°æ®æ¸…æ´—ä»£ç  import DataCleaner
from b_æ¨¡å‹è®­ç»ƒä»£ç  import GNNTrainer, GraphBuilder


class ModelPredictor:
    """GNNæ¨¡å‹é¢„æµ‹ä¸ç»“æœåˆ†æç±»"""
    
    def __init__(self, model_dir='model/', test_dir='test/', output_dir='results/'):
        """
        åˆå§‹åŒ–é¢„æµ‹å™¨
        
        Parameters:
        -----------
        model_dir : str
            æ¨¡å‹ç›®å½•
        test_dir : str
            æµ‹è¯•æ•°æ®ç›®å½•
        output_dir : str
            ç»“æœè¾“å‡ºç›®å½•
        """
        self.model_dir = model_dir
        self.test_dir = test_dir
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        # åŠ è½½ç»„ä»¶
        self.trainer = GNNTrainer(model_dir=model_dir)
        self.cleaner = DataCleaner(output_dir=model_dir)
        self.cleaner.load_preprocessor()
        
    def load_model(self, filename='gnn_model.pth'):
        """
        åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
        
        Parameters:
        -----------
        filename : str
            æ¨¡å‹æ–‡ä»¶å
        """
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        model_path = os.path.join(self.model_dir, filename)
        if not os.path.exists(model_path):
            # å°è¯•åŠ è½½æœ€ä½³æ¨¡å‹
            best_model_path = os.path.join(self.model_dir, 'gnn_model_best.pth')
            if os.path.exists(best_model_path):
                print(f"æœªæ‰¾åˆ° {filename}ï¼Œå°è¯•åŠ è½½æœ€ä½³æ¨¡å‹: gnn_model_best.pth")
                filename = 'gnn_model_best.pth'
            else:
                print("=" * 60)
                print("âŒ é”™è¯¯ï¼šæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼")
                print("=" * 60)
                print(f"\næœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
                print(f"ä¹Ÿæœªæ‰¾åˆ°æœ€ä½³æ¨¡å‹: {best_model_path}")
                print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š")
                print("   è¯·å…ˆè¿è¡Œè®­ç»ƒä»£ç ç”Ÿæˆæ¨¡å‹æ–‡ä»¶ï¼š")
                print("   python GNN/b_æ¨¡å‹è®­ç»ƒä»£ç .py")
                print("\n   è®­ç»ƒå®Œæˆåä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š")
                print("   - model/gnn_model.pth (æœ€ç»ˆæ¨¡å‹)")
                print("   - model/gnn_model_best.pth (æœ€ä½³æ¨¡å‹)")
                print("=" * 60)
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}\nè¯·å…ˆè¿è¡Œè®­ç»ƒä»£ç : python GNN/b_æ¨¡å‹è®­ç»ƒä»£ç .py")
        
        self.trainer.load_model(filename)
        print(f"æ¨¡å‹ç±»å‹: GNN ({self.trainer.model_type})")
        if self.trainer.classes is not None:
            print(f"ç±»åˆ«æ•°: {len(self.trainer.classes)}")
    
    def predict_single_sample(self, X_sample):
        """
        é¢„æµ‹å•ä¸ªæ ·æœ¬ï¼ˆç”¨äºæ—¶å»¶æµ‹è¯•ï¼‰
        
        Parameters:
        -----------
        X_sample : ndarray
            å•ä¸ªæ ·æœ¬ç‰¹å¾å‘é‡ï¼ˆåŸå§‹ç‰¹å¾ï¼Œæœªæ ‡å‡†åŒ–ï¼‰
        
        Returns:
        --------
        prediction : int
            é¢„æµ‹ç±»åˆ«
        """
        if self.trainer.model is None:
            raise ValueError("æ¨¡å‹å°šæœªåŠ è½½")
        
        # æ ‡å‡†åŒ–
        if X_sample.ndim == 1:
            X_sample = X_sample.reshape(1, -1)
        
        X_scaled = self.cleaner.transform_features(X_sample, is_train=False)
        
        # æ„å»ºå›¾ï¼ˆéœ€è¦çª—å£æ•°æ®ï¼Œè¿™é‡Œä½¿ç”¨å•ä¸ªæ ·æœ¬é‡å¤æ„å»ºçª—å£ï¼‰
        window_size = self.trainer.graph_builder.window_size
        if len(X_scaled) < window_size:
            # å¦‚æœæ ·æœ¬æ•°ä¸è¶³ï¼Œé‡å¤æœ€åä¸€ä¸ªæ ·æœ¬
            X_window = np.vstack([X_scaled] * window_size)
        else:
            # ä½¿ç”¨æœ€åwindow_sizeä¸ªæ ·æœ¬
            X_window = X_scaled[-window_size:]
        
        # æ„å»ºå›¾
        graph = self.trainer.graph_builder.build_graph(X_window)
        
        # é¢„æµ‹
        self.trainer.model.eval()
        with torch.no_grad():
            batch = Batch.from_data_list([graph])
            out = self.trainer.model(batch.x, batch.edge_index, batch.batch)
            prediction = out.argmax(dim=1).item()
        
        return prediction
    
    def predict_batch(self, X_batch):
        """
        æ‰¹é‡é¢„æµ‹
        
        Parameters:
        -----------
        X_batch : ndarray
            æ‰¹é‡ç‰¹å¾çŸ©é˜µï¼ˆåŸå§‹ç‰¹å¾ï¼Œæœªæ ‡å‡†åŒ–ï¼‰
        
        Returns:
        --------
        predictions : ndarray
            é¢„æµ‹ç±»åˆ«æ•°ç»„
        """
        if self.trainer.model is None:
            raise ValueError("æ¨¡å‹å°šæœªåŠ è½½")
        
        # æ ‡å‡†åŒ–
        X_scaled = self.cleaner.transform_features(X_batch, is_train=False)
        
        # æ„å»ºå›¾
        graphs = self.trainer.build_graphs_from_data(X_scaled, 
                                                       np.zeros(len(X_scaled)))
        
        # æ‰¹é‡é¢„æµ‹
        self.trainer.model.eval()
        predictions = []
        
        with torch.no_grad():
            for i in range(0, len(graphs), self.trainer.batch_size):
                batch_graphs = graphs[i:i+self.trainer.batch_size]
                batch = Batch.from_data_list(batch_graphs)
                out = self.trainer.model(batch.x, batch.edge_index, batch.batch)
                pred = out.argmax(dim=1).cpu().numpy()
                predictions.extend(pred)
        
        # å°†é¢„æµ‹ç»“æœæ˜ å°„å›åŸå§‹æ ·æœ¬
        final_predictions = np.zeros(len(X_batch), dtype=int)
        window_size = self.trainer.graph_builder.window_size
        
        if len(predictions) > 0:
            # å‰window_size-1ä¸ªæ ·æœ¬ä½¿ç”¨ç¬¬ä¸€ä¸ªé¢„æµ‹
            final_predictions[:window_size-1] = predictions[0]
            
            # åç»­æ ·æœ¬ä½¿ç”¨å¯¹åº”é¢„æµ‹
            for i in range(window_size-1, len(X_batch)):
                seq_idx = i - (window_size - 1)
                if seq_idx < len(predictions):
                    final_predictions[i] = predictions[seq_idx]
                else:
                    final_predictions[i] = predictions[-1]
        
        return final_predictions
    
    def calculate_detection_latency(self, X_sample, n_iterations=1000):
        """
        è®¡ç®—æ£€æµ‹æ—¶å»¶
        
        Parameters:
        -----------
        X_sample : ndarray
            å•ä¸ªæ ·æœ¬ç‰¹å¾å‘é‡
        n_iterations : int
            è¿­ä»£æ¬¡æ•°
        
        Returns:
        --------
        latency_stats : dict
            æ—¶å»¶ç»Ÿè®¡ä¿¡æ¯
        """
        if self.trainer.model is None:
            raise ValueError("æ¨¡å‹å°šæœªåŠ è½½")
        
        print(f"\nè®¡ç®—æ£€æµ‹æ—¶å»¶ï¼ˆè¿­ä»£ {n_iterations} æ¬¡ï¼‰...")
        
        latencies = []
        
        for i in range(n_iterations):
            start_time = time.perf_counter()
            
            # é¢„æµ‹
            _ = self.predict_single_sample(X_sample)
            
            end_time = time.perf_counter()
            latency = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            latencies.append(latency)
        
        latencies = np.array(latencies)
        
        latency_stats = {
            'mean_ms': float(np.mean(latencies)),
            'median_ms': float(np.median(latencies)),
            'std_ms': float(np.std(latencies)),
            'min_ms': float(np.min(latencies)),
            'max_ms': float(np.max(latencies)),
            'p95_ms': float(np.percentile(latencies, 95)),
            'p99_ms': float(np.percentile(latencies, 99))
        }
        
        print(f"å¹³å‡æ—¶å»¶: {latency_stats['mean_ms']:.4f} ms")
        print(f"ä¸­ä½æ•°æ—¶å»¶: {latency_stats['median_ms']:.4f} ms")
        print(f"P95æ—¶å»¶: {latency_stats['p95_ms']:.4f} ms")
        print(f"P99æ—¶å»¶: {latency_stats['p99_ms']:.4f} ms")
        
        return latency_stats
    
    def calculate_computational_efficiency(self, X_batch):
        """
        è®¡ç®—è®¡ç®—æ•ˆç‡ï¼ˆæ ·æœ¬/ç§’ï¼‰
        
        Parameters:
        -----------
        X_batch : ndarray
            æ‰¹é‡ç‰¹å¾çŸ©é˜µ
        
        Returns:
        --------
        samples_per_second : float
            æ¯ç§’å¤„ç†çš„æ ·æœ¬æ•°
        """
        if self.trainer.model is None:
            raise ValueError("æ¨¡å‹å°šæœªåŠ è½½")
        
        print(f"\nè®¡ç®—è®¡ç®—æ•ˆç‡ï¼ˆæ‰¹é‡å¤§å°: {len(X_batch)}ï¼‰...")
        
        # é¢„çƒ­
        _ = self.predict_batch(X_batch[:min(10, len(X_batch))])
        
        # æ­£å¼æµ‹è¯•
        start_time = time.perf_counter()
        _ = self.predict_batch(X_batch)
        end_time = time.perf_counter()
        
        elapsed_time = end_time - start_time
        samples_per_second = len(X_batch) / elapsed_time if elapsed_time > 0 else 0
        
        print(f"å¤„ç† {len(X_batch)} ä¸ªæ ·æœ¬è€—æ—¶: {elapsed_time:.4f} ç§’")
        print(f"è®¡ç®—æ•ˆç‡: {samples_per_second:.2f} æ ·æœ¬/ç§’")
        
        return samples_per_second
    
    def calculate_model_size(self):
        """
        è®¡ç®—æ¨¡å‹å¤§å°
        
        Returns:
        --------
        model_info : dict
            æ¨¡å‹ä¿¡æ¯
        """
        if self.trainer.model is None:
            raise ValueError("æ¨¡å‹å°šæœªåŠ è½½")
        
        # è®¡ç®—å‚æ•°é‡
        total_params = sum(p.numel() for p in self.trainer.model.parameters())
        trainable_params = sum(p.numel() for p in self.trainer.model.parameters() if p.requires_grad)
        
        # è®¡ç®—æ¨¡å‹æ–‡ä»¶å¤§å°
        model_file = os.path.join(self.model_dir, 'gnn_model.pth')
        if os.path.exists(model_file):
            file_size_bytes = os.path.getsize(model_file)
            file_size_kb = file_size_bytes / 1024
            file_size_mb = file_size_bytes / (1024 * 1024)
        else:
            file_size_bytes = 0
            file_size_kb = 0
            file_size_mb = 0
        
        # ä¼°ç®—å†…å­˜å ç”¨ï¼ˆå‚æ•° + æ¿€æ´»å€¼ï¼‰
        param_memory_mb = total_params * 4 / (1024 * 1024)  # float32 = 4 bytes
        estimated_memory_mb = param_memory_mb * 2  # ä¼°ç®—ï¼ˆå‚æ•° + æ¿€æ´»å€¼ï¼‰
        
        model_info = {
            'total_params': int(total_params),
            'trainable_params': int(trainable_params),
            'file_size_bytes': int(file_size_bytes),
            'file_size_kb': float(file_size_kb),
            'file_size_mb': float(file_size_mb),
            'estimated_memory_mb': float(estimated_memory_mb),
            'model_type': self.trainer.model_type,
            'input_dim': int(self.trainer.input_dim),
            'hidden_dim': int(self.trainer.hidden_dim),
            'output_dim': int(self.trainer.output_dim)
        }
        
        print(f"\næ¨¡å‹ä¿¡æ¯:")
        print(f"  æ€»å‚æ•°é‡: {total_params:,}")
        print(f"  å¯è®­ç»ƒå‚æ•°é‡: {trainable_params:,}")
        print(f"  æ¨¡å‹æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB ({file_size_kb:.2f} KB)")
        print(f"  ä¼°ç®—å†…å­˜å ç”¨: {estimated_memory_mb:.2f} MB")
        
        return model_info
    
    def predict_test_file(self, test_file_path):
        """
        é¢„æµ‹æµ‹è¯•æ–‡ä»¶å¹¶æ›´æ–°resultåˆ—
        
        Parameters:
        -----------
        test_file_path : str
            æµ‹è¯•æ–‡ä»¶è·¯å¾„
        """
        print(f"\né¢„æµ‹æµ‹è¯•æ–‡ä»¶: {test_file_path}")
        
        # åŠ è½½æµ‹è¯•æ•°æ®
        df_test = pd.read_csv(test_file_path)
        print(f"æµ‹è¯•æ•°æ®å½¢çŠ¶: {df_test.shape}")
        
        # å‡†å¤‡ç‰¹å¾
        exclude_cols = ['time', 'group_name', 'sufficient_window_size',
                        'labelMovement', 'result', 'labelArea']
        feature_cols = [col for col in df_test.columns if col not in exclude_cols]
        
        if self.cleaner.feature_columns is not None:
            feature_cols = [col for col in self.cleaner.feature_columns if col in feature_cols]
            X_test = df_test[feature_cols].copy()
            missing_cols = set(self.cleaner.feature_columns) - set(feature_cols)
            if missing_cols:
                print(f"è­¦å‘Š: æµ‹è¯•æ•°æ®ç¼ºå°‘ç‰¹å¾åˆ—: {len(missing_cols)} ä¸ª")
                for col in missing_cols:
                    X_test[col] = 0
            X_test = X_test[self.cleaner.feature_columns]
        else:
            X_test = df_test[feature_cols].copy()
        
        # é¢„æµ‹
        predictions = self.predict_batch(X_test.values)
        
        # æ›´æ–°resultåˆ—
        df_test['result'] = predictions
        
        # ä¿å­˜
        df_test.to_csv(test_file_path, index=False)
        print(f"é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {test_file_path}")
        
        return df_test


def main():
    """ä¸»å‡½æ•°ï¼šé¢„æµ‹æµ‹è¯•æ•°æ®"""
    print("=" * 60)
    print("GNNæ¨¡å‹è°ƒç”¨ä¸ç»“æœåˆ†æ")
    print("=" * 60)
    
    # åˆ›å»ºé¢„æµ‹å™¨
    predictor = ModelPredictor(
        model_dir='model/',
        test_dir='test/',
        output_dir='results/'
    )
    
    # åŠ è½½æ¨¡å‹ï¼ˆå°è¯•åŠ è½½æœ€ä½³æ¨¡å‹ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åŠ è½½æ™®é€šæ¨¡å‹ï¼‰
    try:
        predictor.load_model('gnn_model.pth')
    except FileNotFoundError:
        # å¦‚æœæ™®é€šæ¨¡å‹ä¸å­˜åœ¨ï¼Œå°è¯•åŠ è½½æœ€ä½³æ¨¡å‹
        try:
            predictor.load_model('gnn_model_best.pth')
        except FileNotFoundError:
            # å¦‚æœéƒ½ä¸å­˜åœ¨ï¼Œç»™å‡ºæç¤ºå¹¶é€€å‡º
            print("\nè¯·å…ˆè¿è¡Œè®­ç»ƒä»£ç ç”Ÿæˆæ¨¡å‹æ–‡ä»¶ï¼")
            return
    
    # é¢„æµ‹æµ‹è¯•æ•°æ®
    test_file_path = 'train/æ¸…æ´—æµ‹è¯•æ•°æ®.csv'
    if os.path.exists(test_file_path):
        predictor.predict_test_file(test_file_path)
    else:
        print(f"æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file_path}")
        print("æç¤ºï¼šè¯·å…ˆè¿è¡Œæ•°æ®æ¸…æ´—ä»£ç ç”Ÿæˆæ¸…æ´—æµ‹è¯•æ•°æ®")
    
    print("\n" + "=" * 60)
    print("é¢„æµ‹å®Œæˆï¼")
    print("=" * 60)


if __name__ == '__main__':
    main()

